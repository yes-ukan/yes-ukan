
<!DOCTYPE html>
<html lang="en">



  <head>
    <style>
      .centered {
            display: flex;
            align-items: center;
            justify-content: center;
            text-align: center;
            line-height: 1.2;
            /* width: 60%; */
        }
        .centered img {
            margin-right: 10px;

        }
        .left-align {
            text-align: left;
            /* width: 60%; */
        }
      body {
          font-family: Arial, sans-serif;
          background-color: #f5f5f5;
          color: #333;
          margin: 0;
          padding: 20px;

      }
      .paper {
          margin-bottom: 20px;
          background-color: #f9f9f9; /* 浅灰色背景 */
          border: 1px solid #ddd;
          border-radius: 5px;
          padding: 20px;
          box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
          
      }
      .paper h2 {
          font-size: 24px;
          font-weight: bold;
          margin-bottom: 10px;
          color: #5c6bc0; /* 柔和的蓝紫色 */
      }
      .paper p {
          font-size: 16px;
          line-height: 1.5;
          color: #666; /* 柔和的灰色 */
      }
      .paper a {
          color: #5c6bc0; /* 柔和的蓝紫色 */
          text-decoration: none;
          transition: color 0.3s ease;
      }
      .paper a:hover {
          color: #3949ab; /* 柔和的深蓝色 */
          text-decoration: underline;
      }
  </style>

    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
      U-KAN Makes Strong Backbone for Medical Image Segmentation and Generation
    </title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <!-- <link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/project.css" media="screen" />
    <link rel="stylesheet" type="text/css" media="screen" href="css/iconize.css" />
    <script src="js/google-code-prettify/prettify.js"></script> -->
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            
            <h2 class="centered">
              <img src="./pic/logo_1.png" alt="" width="100" height="100">
              <div>
                  U-KAN Makes Strong Backbone for Medical <br>
                  Image Segmentation and Generation
              </div>
          </h2>
            <h4 style="color:#5a6268;">Arxiv 2024 </h4>
            <hr>
            <h6>
                <a href="https://xggnet.github.io/" target="_blank">Chenxin Li</a><sup>*</sup>,
                <a href="https://xinyuliu-jeffrey.github.io/" target="_blank">Xinyu Liu</a><sup>*</sup>,
                <a href="https://wymancv.github.io/wuyang.github.io/" target="_blank">Wuyang Li</a><sup>*</sup>,
                <a href="https://scholar.google.com/citations?user=AM7gvyUAAAAJ&hl=en" target="_blank">Cheng Wang</a><sup>*</sup>,
                <a href="https://github.com/LiuHengyu321" target="_blank">Hengyu Liu</a><sup></sup>,
                <a href="http://www.ee.cuhk.edu.hk/~yxyuan/people/people.htm" target="_blank">Yixuan Yuan</a><sup></sup>

              </h6>
            <p>
                <sup></sup>The Chinese University of Hong Kong &nbsp;&nbsp;
            </p>

            <div class="row justify-content-center">
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://arxiv.org/abs/2403.11050" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/CUHK-AIM-Group/U-KAN" role="button"  target="_blank">
                    <i class="fa fa-github-alt"></i> Code </a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="#bib" role="button"  target="_blank">
                    <i class="fa fa-database"></i> BibTex </a> </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
            <hr style="margin-top:0px">
            <!-- <h6 style="color:#8899a5">  -->
              <!-- SyncDreamer is able to directly generate multiview consistent images, which allows 3D reconstruction by NeuS or NeRF without SDS loss.  -->
              <!-- TL;DR:<i>Endora</i> enables the <b>high-fidelity medical video generation</b> on endoscopy scenes and demonstrates the <b>versatile ability through successful applications</b> in video-based disease diagnosis and 3D surgical scene reconstruction. -->
            <!-- </h6> -->

              <!-- <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                  <source src="video/teaser.mp4" type="video/mp4">
              </video> -->

			        <br>

          <p class="text-left">
            U-Net has become a cornerstone in various visual applications such as image segmentation and diffusion probability models. 
            <br>
            <br>
            While numerous innovative designs and improvements have been introduced by incorporating transformers or MLPs, the networks are still limited to linearly modeling patterns as well as the deficient interpretability. To address these challenges, our intuition is inspired by the impressive results of the Kolmogorov-Arnold Networks (KANs) in terms of
            accuracy and interpretability, which reshape the neural network learning via the
            stack of non-linear learnable activation functions derived from the Kolmogorov-
            Anold representation theorem. 
            <br>
            <br>
            Specifically, in this paper, we explore the untapped
            potential of KANs in improving backbones for vision tasks. 
            <br>
            <br>
            We investigate, modify and re-design the established U-Net pipeline by integrating the dedicated KAN
            layers on the tokenized intermediate representation, termed U-KAN. Rigorous medical image segmentation benchmarks verify the superiority of U-KAN by higher
            accuracy even with less computation cost. 
            <br>
            <br>
            We further delved into the potential of U-KAN as an alternative U-Net noise predictor in diffusion models, demonstrating
            its applicability in generating task-oriented model architectures. 
            <br>
            <br>
            These endeavours unveil valuable insights and sheds light on the prospect that with U-KAN, you can
            make strong backbone for medical image segmentation and generation.
          
          
          </p>

        <p class="text-center">
          <!-- Reverse process of SyncDreamer's multiview diffusion. -->
          <!-- Sampled realistic endoscopy videos by <i>Endora</i>.  -->
        </p>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Network</h2>
            <hr style="margin-top:0px">
            <img src="./pic/framework.jpg" alt="" width="1000" height="600">
            <br>
            <br>
            <div class="text-left">
              Overview of U-KAN pipeline. After feature extraction by several convolution stages, the
              intermediate maps are tokenized and processed by stacked KAN layers. The time embedding is only
              injected into the KAN blocks when applied for Diffusion U-KAN.
            <div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Segmentation Results </h2>
            <hr style="margin-top:0px">
            <h3> Visual Results </h3>
            <img src="./pic/seg.jpg" alt="" width="1000" height="500">
            <hr style="margin-top:0px">
            <h3> Quantitative Results </h3>
            <img src="./pic/res_1.png" alt="" width="800" height="250">
            <img src="./pic/res_2.png" alt="" width="800" height="300">
      </div>
    </div>
  </section>
  <br>
  
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>Generative Results</h2>
            <hr style="margin-top:0px">
            <img src="./pic/gen.jpg" alt="" width="1000" height="800">
    </div>
  </div>
</section>
<br>

  
  

<!--   
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h2>More results</h2>
            <hr style="margin-top:0px">
            <video width="80%" playsinline="" autoplay="autoplay" loop="loop" preload="" muted="">
                <source src="video/more_results.mp4" type="video/mp4">
            </video>

          <p class="text-center">
              Test images are downloaded from the Internet and some of them are from <a href="https://wiki.biligame.com/ys/%E9%A6%96%E9%A1%B5" target="_blank">Genshin Impact Wiki</a>.
          </p>
        </div>
      </div>
    </div>
  </section>
  <br> -->

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
<code id="bib">@article{li2024endora,
  author    = {Chenxin Li and Xinyu Liu and Wuyang Li and Cheng Wang and Hengyu Liu and Yixuan Yuan},
  title     = {U-KAN Makes Strong Backbone for Medical Image Segmentation and Generation},
  journal   = {arXiv preprint},
  year      = {2024}
}</code>
              </pre>
          <hr>
      </div>
    </div>
  </div>

  <!-- citing
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
          <hr style="margin-top:0px">
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
                <code>@article{li2024endora,
                    author    = {Chenxin Li and Hengyu Liu and Yifan Liu and Brandon Y. Feng, and Wuyang Li and Xinyu Liu, Zhen Chen and Jing shao and Yixuan Yuan},
                    title     = {Endora: Video Generation Models as Endoscopy Simulators},
                    journal   = {Arxiv},
                    year      = {2024},
                  } </code>
              </pre>
          <hr>
      </div>
    </div>
  </div> -->



  <footer class="text-center" style="margin-bottom:10px">
      Modified from <a href="https://lioryariv.github.io/idr/" target="_blank">this website</a>
  </footer>

</body>
</html>
